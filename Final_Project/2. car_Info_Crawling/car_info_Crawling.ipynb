{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419f6320",
   "metadata": {},
   "source": [
    "## 네이버 차량 제원 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20f458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# 네이버 검색\n",
    "url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=\"\n",
    "\n",
    "# 자동차 정보를 검색\n",
    "def search_car(url, keyword):\n",
    "    # 검색 URL 생성\n",
    "    search_url = url + keyword + \" 정보\"\n",
    "    # HTTP 요청 보내기\n",
    "    response = req.get(search_url)\n",
    "    # HTML 파싱\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # 정보 섹션 찾기\n",
    "    info_section = soup.find(class_=\"info\")\n",
    "    # 만약 정보 섹션을 찾지 못했다면\n",
    "    if info_section is None:\n",
    "        print(f\"{keyword}에 대한 정보를 찾을 수 없습니다.\")\n",
    "        return None, None, None, keyword\n",
    "    # 정보 추출\n",
    "    info = info_section.find_all(\"dt\")\n",
    "    info2 = info_section.find_all(\"dd\")\n",
    "    # span 태그 제거\n",
    "    for infos in info2:\n",
    "        span = infos.find(\"span\")\n",
    "        if span:\n",
    "            span.decompose()\n",
    "    # 검색 URL과 정보 반환\n",
    "    return search_url, info, info2, keyword\n",
    "\n",
    "# 데이터프레임을 CSV 파일로 저장\n",
    "def save_to_csv(df, filename='car_info.csv'):\n",
    "    df.to_csv(filename, mode='a', index=False, encoding=\"utf-8-sig\")\n",
    "# 빈 데이터프레임 생성\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "class_names={\n",
    "    \"0\":\"티볼리\",\"1\":\"팰리세이드\",\"2\":\"포터2\",\"3\":\"i30\",\"4\":\"G4렉스턴\",\"5\":\"K3\",\"6\":\"K5\",\"7\":\"K7\",\"8\":\"K9\",\"9\":\"QM3\",\"10\":\"QM6\",\"11\":\"SM3\",\"12\":\"SM5\",\n",
    "    \"13\":\"SM6\", \"14\":\"SM7\", \"15\":\"XM3\", \"16\":\"그랜저\", \"17\":\"니로\", \"18\":\"다마스\", \"19\":\"레이\", \"20\":\"렉스턴스포츠\",\"21\":\"맥스크루즈\", \"22\":\"모닝\", \n",
    "    \"23\":\"모하비\", \"24\":\"베뉴\", \"25\":\"벨로스터\", \"26\":\"봉고3\", \"27\":\"셀토스\", \"28\":\"스타렉스\", \"29\":\"스토닉\", \"30\":\"스팅어\", \"31\":\"스포티지\",\n",
    "    \"32\":\"싼타페\", \"33\":\"쏘나타\", \"34\":\"쏘렌토\", \"35\":\"쏘울\", \"36\":\"아반떼\", \"37\":\"아이오닉\", \"38\":\"엑센트\", \"39\":\"카니발\", \"40\":\"코나\",\n",
    "    \"41\":\"코란도\", \"42\":\"코란도투리스모\", \"43\":\"코란도C\", \"44\":\"투싼\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c019959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 이름 리스트 생성\n",
    "class_name_list = list(class_names.values())\n",
    "# 각 클래스 이름에 대해 자동차 정보 검색\n",
    "for keyword in class_name_list:\n",
    "    # 자동차 정보 검색 함수 호출\n",
    "    urls, info, info2, _ = search_car(url, keyword)\n",
    "    # 검색 결과가 없다면 다음 키워드로 넘어감\n",
    "    if urls is None:\n",
    "        continue\n",
    "    # 정보를 딕셔너리로 페어링\n",
    "    paired_data = {title: data for title, data in zip(info, info2)}\n",
    "    # '차종' 정보 추가\n",
    "    paired_data['차종'] = keyword\n",
    "    # 딕셔너리를 DataFrame으로 변환\n",
    "    df_temp = pd.DataFrame([paired_data])\n",
    "    # DataFrame의 열 순서 재정렬\n",
    "    cols = list(df_temp.columns)\n",
    "    if '차종' in cols:\n",
    "        cols.insert(0, cols.pop(cols.index('차종')))\n",
    "        df_temp = df_temp.reindex(columns=cols)\n",
    "    # 전체 DataFrame에 현재 DataFrame 추가\n",
    "    df_all = pd.concat([df_all, df_temp], ignore_index=True)\n",
    "# 결과를 CSV 파일로 저장\n",
    "save_to_csv(df_all)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
